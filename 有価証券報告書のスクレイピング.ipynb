{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####有価証券報告書のスクレイピング#####\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##企業データの読み込みとクレンジング\n",
    "#データの読み込み\n",
    "company_info1 = pd.read_csv(\"D:/Statistics/data/stock_price/st-jp/company_info.csv\")\n",
    "index = np.where(np.in1d(company_info1[\"業種\"], np.array([\"ETF\", \"ETN\", \"REIT\", \"カントリーF\", \"インフラF\"]))==False)[0]\n",
    "company_info1 = company_info1.iloc[index]\n",
    "company_info1.index = np.arange(company_info1.shape[0])\n",
    "company_info2 = pd.read_csv(\"D:/Statistics/data/finance_data/stocklist.csv\")\n",
    "company_info2 = company_info2.rename(columns={\"銘柄コード\": \"コード\", \"市場名\": \"取引市場\", \"業種分類\": \"業種\"})\n",
    "index = np.where(np.in1d(company_info2[\"業種\"], np.array([\"REIT銘柄一覧\"]))==False)[0]\n",
    "company_info2 = company_info2.iloc[index]\n",
    "company_info2.index = np.arange(company_info2.shape[0])\n",
    "\n",
    "#データの結合\n",
    "company_info1 = company_info1[[\"コード\", \"銘柄名\", \"取引市場\", \"業種\"]]\n",
    "company_info2 = company_info2[[\"コード\", \"銘柄名\", \"取引市場\", \"業種\"]]\n",
    "company_info = pd.concat((company_info1, company_info2), axis=0)\n",
    "company_info.index = np.arange(company_info.shape[0])\n",
    "\n",
    "#変数を共通化\n",
    "company = company_info[[\"コード\", \"銘柄名\"]].iloc[np.where(company_info[[\"コード\"]].duplicated()==False)[0]]\n",
    "company_info[\"銘柄名\"] = pd.merge(company_info[[\"コード\"]], company, on=\"コード\", how=\"left\")[\"銘柄名\"]\n",
    "industry = np.array([['水産・農林業', '卸売業', '建設業', '非鉄金属', '鉱業', '機械', 'サービス業', '金属製品',\n",
    "                      '情報・通信', '食料品', '医薬品', '不動産業', '陸運業', 'その他金融業', '小売業', 'その他製品',\n",
    "                      '繊維製品', '電気機器', 'ガラス・土石製品', '証券業', '輸送用機器', '石油・石炭製品', '化学',\n",
    "                      'パルプ・紙', '精密機器', 'ゴム製品', '鉄鋼', '銀行業', '保険業', '倉庫・運輸関連業', '海運業',\n",
    "                      '空運業', '電気・ガス業'],\n",
    "                   ['水産・農林', '卸売', '建設業', '非鉄金属', '鉱業', '機械', 'サービス', '金属製品',\n",
    "                    '情報通信', '食料品', '医薬品', '不動産', '陸運', 'その他金融', '小売', 'その他製品', \n",
    "                    '繊維製品', '電気機器', 'ガラス土石', '証券・先物', '輸送用機器', '石油・石炭', '化学',\n",
    "                    'パルプ・紙', '精密機器', 'ゴム製品', '鉄鋼', '銀行', '保険', '倉庫・運輸', '海運', \n",
    "                    '空運', '電気・ガス']])\n",
    "industry_vec = np.array(company_info[\"業種\"])\n",
    "for j in range(industry.shape[1]):\n",
    "    index = np.where(industry_vec==industry[0, j])[0]\n",
    "    industry_vec[index] = np.array(industry[1, j], dtype=\"object\")\n",
    "company_info[\"業種\"] = industry_vec\n",
    "market = np.array([['東証1部', 'JQS', 'JQG', 'マザーズ', '東証2部', '福証Q', '名証2部', '札証', '福証',\n",
    "                    '名証1部', '札証A', '名証C', '東証'],\n",
    "                   ['東証1部', '東証JQS', '東証JQG', 'マザーズ', '東証2部', '福岡Q', '名証2部', '札証', \"福証\",\n",
    "                    '名証1部',  '札幌ア', '名古屋セ', '東証']])\n",
    "market_vec = np.array(company_info[\"取引市場\"])\n",
    "for j in range(market.shape[1]):\n",
    "    index = np.where(market_vec==market[0, j])[0]\n",
    "    market_vec[index] = np.array(market[1, j], dtype=\"object\")\n",
    "company_info[\"取引市場\"] = market_vec\n",
    "\n",
    "#重複を削除\n",
    "company_info = company_info.iloc[np.where(company_info[\"コード\"].duplicated()==False)[0]]\n",
    "company_info.index = np.arange(company_info.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##有価証券報告書を取得するための情報をスクレイピング\n",
    "#待ち時間を設定\n",
    "second = np.arange(1, 5)\n",
    "prob = np.repeat(1.0/second.shape[0], second.shape[0])\n",
    "\n",
    "#データの格納用配列\n",
    "code = np.array(company_info[\"コード\"])\n",
    "n = company_info.shape[0]\n",
    "ticker_list = [i for i in range(n)]\n",
    "company_list = [i for i in range(n)]\n",
    "info_list = [i for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#すべての企業の有価証券報告書を取得するための情報を取得\n",
    "for i in range(n):\n",
    "    print([i, company_info[\"銘柄名\"].iloc[i]])\n",
    "    \n",
    "    #URLを取得\n",
    "    url = \"http://www.kabupro.jp/yuho/{code}.htm\"\n",
    "    r = requests.get(url.format(code=code[i]))\n",
    "\n",
    "    #短信のリンクを取得\n",
    "    r.encoding = r.apparent_encoding\n",
    "    html_text = r.text\n",
    "    get_data = re.findall(\"[有価証券報告書|四半期報告書].+a href=.+日\", html_text)\n",
    "\n",
    "    #テキストを分解して必要情報を取得\n",
    "    m = len(get_data)\n",
    "    report = np.array(np.repeat(\"\", m), dtype=\"object\")\n",
    "    season = np.array(np.repeat(\"\", m), dtype=\"object\")\n",
    "    start_period = np.array(np.repeat(\"\", m), dtype=\"object\")\n",
    "    end_period = np.array(np.repeat(\"\", m), dtype=\"object\")\n",
    "    url = np.array(np.repeat(\"\", m), dtype=\"object\")\n",
    "    for j in range(m):\n",
    "        report0 = re.search(\".+報告書\", get_data[j])\n",
    "        season0 = re.search(\"第.+期\", get_data[j])\n",
    "        period0= re.search(\"平成.+\", get_data[j])\n",
    "        url0 = re.search(\"a href=.+htm\", get_data[j])\n",
    "        if report0 is not None:\n",
    "            report[j] = report0[0]\n",
    "        if season0 is not None:\n",
    "            season[j] = season0[0]\n",
    "        if period0 is not None:\n",
    "            split_period = re.split(\"-\", period0[0])\n",
    "            start_period[j] = split_period[0]\n",
    "            end_period[j] = split_period[1]\n",
    "        if url0 is not None:\n",
    "            url[j] = \"http://www.kabupro.jp\" + url0[0][9:]\n",
    "    ticker0 = np.repeat(code[i], m)\n",
    "    company0 = np.array(company_info[[\"銘柄名\", \"取引市場\", \"業種\"]].iloc[np.repeat(i, m)])\n",
    "    info0 = np.vstack((report, season, start_period, end_period, url)).T\n",
    "\n",
    "    #リストに格納\n",
    "    ticker_list[i] = ticker0\n",
    "    company_list[i] = company0\n",
    "    info_list[i] = info0\n",
    "    \n",
    "    #待ち時間\n",
    "    weight_time = np.dot(np.random.multinomial(1, prob, 1), second)\n",
    "    time.sleep(weight_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#リストをデータフレームに変換\n",
    "ticker = np.array(list(itertools.chain(*[ticker_list[i] for i in range(m)])))\n",
    "company = np.array(list(itertools.chain(*[company_list[i] for i in range(m)])))\n",
    "info = np.array(list(itertools.chain(*[info_list[i] for i in range(m)])))\n",
    "ticker_df = pd.DataFrame({\"ticker\": ticker})\n",
    "company_df = pd.DataFrame(company)\n",
    "company_df.columns = [\"company\", \"market\", \"industry\"]\n",
    "info_df = pd.DataFrame(info)\n",
    "info_df.columns = [\"report\", \"season\", \"start_jp\", \"end_jp\", \"url\"]\n",
    "df = pd.concat((ticker_df, company_df, info_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##和暦を西暦に変換\n",
    "#カレンダーの読み込み\n",
    "N = df.shape[0]\n",
    "calender = pd.read_csv(\"C:/statistics/data/finance_data/jpn_calender.csv\")\n",
    "finance_date = pd.read_csv(\"C:/statistics/data/finance_data/finance_date_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#日付を分割\n",
    "start_date = np.zeros((N, 3), dtype=\"int16\")\n",
    "end_date = np.zeros((N, 3), dtype=\"int16\")\n",
    "start_period = np.repeat(0, N)\n",
    "end_period = np.repeat(0, N)\n",
    "temp1 = df[\"start_jp\"].str[2:].str.split(\"[年|月|日]\")\n",
    "temp2 = df[\"end_jp\"].str[2:].str.split(\"[年|月|日]\")\n",
    "\n",
    "#和暦を西暦に変換\n",
    "for i in range(N):\n",
    "    index1 = np.where(calender[\"jpn_calender\"]==np.array(temp1[i][0], dtype=\"int\"))[0]\n",
    "    index2 = np.where(calender[\"jpn_calender\"]==np.array(temp2[i][0], dtype=\"int\"))[0]\n",
    "    start_date[i, 0] = np.array(calender[\"calender\"].iloc[index1], dtype=\"int16\")\n",
    "    end_date[i, 0] = np.array(calender[\"calender\"].iloc[index2], dtype=\"int16\")\n",
    "    start_date[i, 1] = np.array(temp1[i][1], dtype=\"int16\")\n",
    "    end_date[i, 1] = np.array(temp2[i][1], dtype=\"int16\")\n",
    "    start_date[i, 2] = np.array(temp1[i][2], dtype=\"int16\")\n",
    "    end_date[i, 2] = np.array(temp2[i][2], dtype=\"int16\")\n",
    "    if len(temp1[i][1])==1:\n",
    "        temp1[i][1] = \"0\" + temp1[i][1]\n",
    "    if len(temp1[i][2])==1:\n",
    "        temp1[i][2] = \"0\" + temp1[i][2]\n",
    "    if len(temp2[i][1])==1:\n",
    "        temp2[i][1] = \"0\" + temp2[i][1]\n",
    "    if len(temp2[i][2])==1:\n",
    "        temp2[i][2] = \"0\" + temp2[i][2]\n",
    "    start_period[i] = np.array(np.array(start_date[i, 0], dtype=\"U\"), dtype=\"object\") + temp1[i][1] + temp1[i][2]\n",
    "    end_period[i] = np.array(np.array(end_date[i, 0], dtype=\"U\"), dtype=\"object\") + temp2[i][1] + temp2[i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データフレームに格納\n",
    "start_df = pd.concat((pd.DataFrame(start_period), pd.DataFrame(start_date)), axis=1)\n",
    "end_df = pd.concat((pd.DataFrame(end_period), pd.DataFrame(end_date)), axis=1)\n",
    "start_df.columns = [\"start_period\", \"start_year\", \"start_month\", \"start_day\"]\n",
    "end_df.columns = [\"end_period\", \"end_year\", \"end_month\", \"end_day\"]\n",
    "target_df = pd.concat((df, start_df, end_df), axis=1)\n",
    "target_df = target_df[[\"ticker\", \"company\", \"market\", \"industry\", \"report\", \"season\", \"start_period\", \"start_jp\", \"start_year\", \n",
    "                       \"start_month\", \"start_day\", \"end_period\", \"end_jp\", \"end_year\", \"end_month\", \"end_day\", \"url\"]]\n",
    "report_type = target_df[\"report\"].str.replace(\"四半期\", \"\")\n",
    "end_period = target_df[\"end_period\"].astype(\"U\")\n",
    "target_df[\"download_url\"] = target_df[\"url\"].str.replace(\"mark\", \"edp\").str.replace(\"htm\", \"pdf\")\n",
    "\n",
    "#保存ファイルネームを設定\n",
    "published = np.array(np.repeat(\"\", target_df.shape[0]), dtype=\"object\")\n",
    "temp = target_df[\"download_url\"].str.split(\"/\")\n",
    "for i in range(target_df.shape[0]):\n",
    "    published[i] = temp[i][4] + temp[i][5].replace(\".pdf\", \"\")\n",
    "target_df[\"filename\"] = \"【\" + published + \"】\" + target_df[\"company\"] + \"_\" + target_df[\"season\"] + report_type + \".pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv(\"D:/Statistics/data/finance_report/report_info.csv\")\n",
    "n = pd.unique(target_df[\"ticker\"]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2413, '日本ケミコン']\n",
      "[2412, 'ニチコン']\n",
      "[2411, '東海理化']\n",
      "[2410, '指月電機製作所']\n",
      "[2409, '大黒屋HD']\n",
      "[2408, '北陸電気工業']\n",
      "[2407, '日東電工']\n",
      "[2406, '双葉電子工業']\n",
      "[2405, 'ユーシン']\n",
      "[2404, 'リード']\n",
      "[2403, '村田製作所']\n",
      "[2402, '日本抵抗器製作所']\n",
      "[2401, '太陽誘電']\n",
      "[2400, '協栄産業']\n",
      "[2399, 'エルナー']\n",
      "[2398, '京セラ']\n",
      "[2397, '松尾電機']\n",
      "[2396, '新光電気工業']\n",
      "[2395, '三井ハイテック']\n",
      "[2394, '浜松ホトニクス']\n",
      "[2393, 'サンコー']\n",
      "[2392, 'ローム']\n",
      "[2391, '大真空']\n",
      "[2390, 'エンプラス']\n",
      "[2389, 'フクダ電子']\n",
      "[2388, '日本ＣＭＫ']\n",
      "[2387, '芝浦電子']\n",
      "[2386, 'ＦＤＫ']\n",
      "[2385, 'ファナック']\n",
      "[2384, 'カシオ計算機']\n",
      "[2383, '日本電子']\n",
      "[2382, '図研']\n",
      "[2381, '日本アビオニクス']\n",
      "[2380, '富士通フロンテック']\n",
      "[2379, 'アイレックス']\n",
      "[2378, 'ＮＫＫスイッチズ']\n",
      "[2377, 'ソフィアHD']\n",
      "[2376, '山一電機']\n",
      "[2375, '双信電機']\n",
      "[2374, '古河電池']\n",
      "[2373, '遠藤照明']\n",
      "[2372, '日本アンテナ']\n",
      "[2371, '日本セラミック']\n",
      "[2370, 'エノモト']\n",
      "[2369, 'ヘリオス_テクノ_HD']\n",
      "[2368, '岡谷電機産業']\n",
      "[2367, 'ウシオ電機']\n",
      "[2366, '岩崎電気']\n",
      "[2365, 'スタンレー電気']\n",
      "[2364, 'レーザーテック']\n",
      "[2363, 'ケル']\n",
      "[2362, 'アバールデータ']\n",
      "[2361, 'アイ・オー・データ機器']\n",
      "[2360, '千代田インテグレ']\n",
      "[2359, 'オプテックスグループ']\n",
      "[2358, '菊水電子工業']\n",
      "[2357, '新日本無線']\n",
      "[2356, 'イリソ電子工業']\n",
      "[2355, 'ジオマテック']\n",
      "[2354, 'コーセル']\n",
      "[2353, '原田工業']\n",
      "[2352, 'デンソー']\n",
      "[2351, '澤藤電機']\n",
      "[2350, 'ＡＳＴＩ']\n",
      "[2349, 'トミタ電機']\n",
      "[2348, 'ツインバード工業']\n",
      "[2347, '北川工業']\n",
      "[2346, 'ダイヤモンド電機']\n",
      "[2345, 'パルステック工業']\n",
      "[2344, 'フェローテックHD']\n",
      "[2343, 'オーデリック']\n",
      "[2342, 'アクモス']\n",
      "[2341, '三社電機製作所']\n",
      "[2340, 'キョウデン']\n",
      "[2339, 'イマジカ・ロボット_HD']\n",
      "[2338, 'ＯＢＡＲＡ_ＧＲＯＵＰ']\n",
      "[2337, 'メガチップス']\n",
      "[2336, '協立電機']\n",
      "[2335, '日本マイクロニクス']\n",
      "[2334, '日本フェンオール']\n",
      "[2333, 'シスメックス']\n",
      "[2332, 'リーダー電子']\n",
      "[2331, 'ＨＩＯＫＩ']\n",
      "[2330, 'エヌエフ回路設計ブロック']\n",
      "[2329, 'ニレコ']\n",
      "[2328, 'ミナトHD']\n",
      "[2327, 'キーエンス']\n",
      "[2326, 'エスペック']\n",
      "[2325, '小野測器']\n",
      "[2324, 'アドバンテスト']\n",
      "[2323, '堀場製作所']\n",
      "[2322, '日本電子材料']\n",
      "[2321, '共和電業']\n",
      "[2320, 'テクノ・セブン']\n",
      "[2319, 'チノー']\n",
      "[2318, '日本光電']\n",
      "[2317, '東亜ディーケーケー']\n",
      "[2316, '中央製作所']\n",
      "[2315, 'アズビル']\n",
      "[2314, '新電元工業']\n",
      "[2313, '横河電機']\n",
      "[2312, 'ＡＫＩＢＡHD']\n",
      "[2311, '船井電機']\n",
      "[2310, '多摩川HD']\n",
      "[2309, '京写']\n",
      "[2308, 'ぷらっとホーム']\n",
      "[2307, 'アライドテレシスHD']\n",
      "[2306, '精工技研']\n",
      "[2305, 'アオイ電子']\n",
      "[2304, '本多通信工業']\n",
      "[2303, '新コスモス電機']\n",
      "[2302, 'リオン']\n",
      "[2301, '大井電気']\n",
      "[2300, 'アイコム']\n",
      "[2299, '伊豆シャボテンリゾート']\n",
      "[2298, 'スミダCorp.']\n",
      "[2297, 'アルパイン']\n",
      "[2296, 'ユニデンHD']\n",
      "[2295, '古野電気']\n",
      "[2294, 'マクセルHD']\n",
      "[2293, 'ＴＯＡ']\n",
      "[2292, '日本航空電子工業']\n",
      "[2291, 'ヒロセ電機']\n",
      "[2290, 'ホシデン']\n",
      "[2289, 'ティアック']\n",
      "[2288, 'ヨコオ']\n",
      "[2287, 'ＳＭＫ']\n",
      "[2286, '名古屋電機工業']\n",
      "[2285, 'クラリオン']\n",
      "[2284, 'フォスター電機']\n",
      "[2283, 'ローランド_ディー．ジー．']\n",
      "[2282, '日本トリム']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c6249d1a45cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m#pdfを保存\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    821\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[1;31m# Close the connection when no data is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##有価証券報告書を取得\n",
    "#待ち時間を設定\n",
    "second = np.arange(1, 3)\n",
    "prob = np.repeat(1.0/second.shape[0], second.shape[0])\n",
    "\n",
    "#ディレクトリを作成\n",
    "index_dup = np.array(np.where(target_df[\"ticker\"].duplicated()==False)[0], dtype=\"int\")\n",
    "dir_name = np.array(target_df[\"ticker\"].iloc[index_dup].astype(\"U\") + \"_\" + target_df[\"company\"].iloc[index_dup])\n",
    "make_path = \"D:/Statistics/data/finance_report/{name}\"\n",
    "for j in range(dir_name.shape[0]):\n",
    "    create_name = make_path.format(name=dir_name[j])\n",
    "    if os.path.exists(create_name)==False:\n",
    "        os.mkdir(create_name)\n",
    "    \n",
    "#取得する企業と保存パスを設定\n",
    "unique_ticker = pd.unique(target_df[\"ticker\"])\n",
    "n = unique_ticker.shape[0]\n",
    "path = \"D:/Statistics/data/finance_report/{dir}/{title}\"\n",
    "\n",
    "#企業毎に短信を取得してローカルに保存\n",
    "for i in range(2414)[::-1]:\n",
    "    \n",
    "    #企業毎の取得urlを定義\n",
    "    index = np.where(target_df[\"ticker\"]==unique_ticker[i])[0]\n",
    "    target_url = np.array(target_df[\"download_url\"].iloc[index])\n",
    "    m = index.shape[0]\n",
    "    print([i, target_df[\"company\"].iloc[index[0]]])\n",
    "\n",
    "    #短信pdfを取得\n",
    "    for j in range(m):\n",
    "        url = target_url[j]\n",
    "        req = requests.get(url)\n",
    "\n",
    "        #pdfを保存\n",
    "        target_name = np.array(target_df[\"filename\"].iloc[index])\n",
    "        target_path = path.format(dir=dir_name[i], title=target_name[j])\n",
    "        myfile = open(target_path, \"wb\")\n",
    "        myfile.write(req.content)\n",
    "        \n",
    "        #待ち時間\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2019-07-12 2282まで終了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.iloc[np.where(target_df[\"filename\"].iloc[index].duplicated())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
