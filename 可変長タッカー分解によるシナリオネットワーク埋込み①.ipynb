{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Heterogeneous Infomation Network Embbedding with Variable order Tucker Decomposition####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import itertools\n",
    "import scipy\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import time, datetime, timedelta\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from numpy.random import *\n",
    "import re\n",
    "import MeCab\n",
    "import neologdn\n",
    "import sys\n",
    "\n",
    "np.random.seed(98537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, no, pattern):\n",
    "    z_id = np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1)\n",
    "    return z_id\n",
    "    if pattern==1:\n",
    "        Z = sparse.coo_matrix((np.repeat(1, n), (no, np.array(z_id))), shape=(n, k))   #スパース行列の設定\n",
    "        return z_id, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "####データの設定####\n",
    "##シナリオの読み込みとクレンジング\n",
    "#データの読み込み\n",
    "company = pd.read_csv(\"D:/Statistics/data/scenario/company.csv\")\n",
    "scenario_df1 = pd.read_csv(\"D:/Statistics/data/scenario/level1_scenario.csv\")\n",
    "scenario_df2 = pd.read_csv(\"D:/Statistics/data/scenario/level2_scenario.csv\")\n",
    "factor_df = pd.read_csv(\"D:/Statistics/data/scenario/Factor.csv\")\n",
    "\n",
    "#読み込んだデータをクレンジング\n",
    "scenario_df1.columns = (scenario_df1.columns).str.replace(\" \", \"\")\n",
    "scenario_df2.columns = (scenario_df2.columns).str.replace(\" \", \"\")\n",
    "factor_df.columns = (factor_df.columns).str.replace(\" \", \"\")\n",
    "company.columns = (company.columns).str.replace(\" \", \"\")\n",
    "columns1 = np.array(scenario_df1.columns)\n",
    "columns2 = np.array(scenario_df2.columns)\n",
    "columns3 = np.array(factor_df.columns)\n",
    "columns4 = np.array(company.columns)\n",
    "for j in range(columns1.shape[0]):\n",
    "    scenario_df1[columns1[j]] = scenario_df1[columns1[j]].str.replace(\"\\\"| \", \"\")\n",
    "for j in range(columns2.shape[0]):\n",
    "    scenario_df2[columns2[j]] = scenario_df2[columns2[j]].str.replace(\"\\\"| \", \"\")\n",
    "for j in range(columns3.shape[0]):\n",
    "    factor_df[columns3[j]] = factor_df[columns3[j]].str.replace(\"\\\"| \", \"\")\n",
    "scenario_df1[\"c.ticker\"] = np.array(scenario_df1[\"c.ticker\"], dtype=\"int\")\n",
    "scenario_df2[\"c.ticker\"] = np.array(scenario_df2[\"c.ticker\"], dtype=\"int\")\n",
    "scenario_df1[\"c.name\"] = pd.merge(scenario_df1[[\"c.ticker\"]], company, on=\"c.ticker\", how=\"left\")[\"c.name\"]\n",
    "scenario_df2[\"c.name\"] = pd.merge(scenario_df2[[\"c.ticker\"]], company, on=\"c.ticker\", how=\"left\")[\"c.name\"]\n",
    "scenario_df21 = scenario_df2[[\"f2.area\", \"f2.predicate\", \"f2.item\", \"f2.trend\", \"f2.element\", \"a.name\", \"a.vector\", \"c.name\", \"c.ticker\"]]\n",
    "scenario_df21 = scenario_df21.rename(columns={\"f2.area\": \"f.area\", \"f2.predicate\": \"f.predicate\", \n",
    "                                              \"f2.item\": \"f.item\", \"f2.trend\": \"f.trend\", \"f2.element\": \"f.element\"})\n",
    "scenario_df1 = pd.concat((scenario_df1, scenario_df21), axis=0)\n",
    "del scenario_df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##解析対象のレコードを抽出して、名寄を行う\n",
    "#scenario1のレコードを抽出\n",
    "index_dup = np.array(np.where(scenario_df1[[\"f.item\", \"f.element\", \"c.name\", \"c.ticker\"]].duplicated()==False)[0], dtype=\"int\")\n",
    "scenario1 = scenario_df1[[\"f.item\", \"f.element\", \"c.name\", \"c.ticker\"]].iloc[index_dup]\n",
    "scenario1.index = np.arange(scenario1.shape[0])\n",
    "\n",
    "#scenario2のレコードを抽出\n",
    "index_dup = np.array(np.where(scenario_df2[[\"f1.item\", \"f1.element\", \"f2.item\", \n",
    "                                            \"f2.element\", \"c.name\", \"c.ticker\"]].duplicated()==False)[0], dtype=\"int\")\n",
    "scenario2 = scenario_df2[[\"f1.item\", \"f1.element\", \"f2.item\", \"f2.element\", \"c.name\", \"c.ticker\"]].iloc[index_dup]\n",
    "scenario2.index = np.arange(scenario2.shape[0])\n",
    "\n",
    "#factorのレコードを抽出\n",
    "index_dup = np.array(np.where(factor_df[[\"f1.item\", \"f1.element\", \"f2.item\", \"f2.element\"]].duplicated()==False)[0], dtype=\"int\")\n",
    "factor = factor_df[[\"f1.item\", \"f1.element\", \"f2.item\", \"f2.element\"]].iloc[index_dup]\n",
    "factor.index = np.arange(factor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##要因および企業のidを生成\n",
    "#itemのidを作成\n",
    "temp = pd.concat((scenario1[\"f.item\"], scenario2[\"f1.item\"], \n",
    "                  scenario2[\"f2.item\"], factor[\"f1.item\"], factor[\"f2.item\"]), axis=0)\n",
    "temp_freq = temp.value_counts()\n",
    "index = np.where(temp_freq >= 3)[0]\n",
    "target = np.array(temp_freq.index[index]); item_freq = temp_freq.iloc[index]\n",
    "temp = temp.iloc[np.where(np.in1d(np.array(temp), target))[0]]\n",
    "item_entity = np.append(np.unique(temp)[1:], \"\")\n",
    "item_id = np.arange(item_entity.shape[0])\n",
    "item = item_entity.shape[0]-1\n",
    "item_df = pd.DataFrame({\"id\": item_id, \"item\": item_entity})\n",
    "\n",
    "#elementのidを作成\n",
    "temp = pd.concat((scenario1[\"f.element\"], scenario2[\"f1.element\"], \n",
    "                  scenario2[\"f2.element\"], factor[\"f1.element\"], factor[\"f2.element\"]), axis=0)\n",
    "temp_freq = temp.value_counts()\n",
    "index = np.where(temp_freq >= 3)[0]\n",
    "target = np.array(temp_freq.index[index]); element_freq = temp_freq.iloc[index]\n",
    "temp = temp.iloc[np.where(np.in1d(np.array(temp), target))[0]]\n",
    "element_entity = np.append(np.unique(temp)[1:], \"\")\n",
    "element_id = np.arange(element_entity.shape[0])\n",
    "element = element_entity.shape[0]-1\n",
    "element_df = pd.DataFrame({\"id\": element_id, \"element\": element_entity})\n",
    "\n",
    "#企業のidを作成\n",
    "temp = pd.concat((scenario1[[\"c.name\", \"c.ticker\"]], scenario2[[\"c.name\", \"c.ticker\"]]), axis=0)\n",
    "temp_freq = temp[\"c.ticker\"].value_counts()\n",
    "index = np.where(temp_freq >= 5)[0]\n",
    "target = np.array(temp_freq.index[index]); company_freq = temp_freq.iloc[index]\n",
    "temp = temp.iloc[np.where(np.in1d(np.array(temp[\"c.ticker\"]), target))[0]]\n",
    "temp.index = np.arange(temp.shape[0])\n",
    "company_df = temp.iloc[np.where(temp.duplicated()==False)[0]]\n",
    "company_df = company_df.sort_values(\"c.ticker\")\n",
    "company_df.index = np.arange(company_df.shape[0])\n",
    "company_df[\"id\"] = np.arange(company_df.shape[0])\n",
    "company_df = company_df[[\"id\", \"c.ticker\", \"c.name\"]]\n",
    "company_df.columns = [\"id\", \"ticker\", \"company\"]\n",
    "company_id = np.array(company_df[\"id\"], dtype=\"int\")\n",
    "\n",
    "#頻度のデータフレームを作成\n",
    "company_freq = pd.DataFrame({\"ticker\": np.array(company_freq.index, dtype=\"int\"), \"freq\": np.array(company_freq, dtype=\"int\")})\n",
    "company_freq = pd.merge(company_freq, company_df, on=\"ticker\", how=\"left\")[[\"id\", \"ticker\", \"company\", \"freq\"]]\n",
    "item_freq = pd.DataFrame({\"item\": np.array(item_freq.index), \"freq\": np.array(item_freq, dtype=\"int\")})\n",
    "item_freq = pd.merge(item_freq, item_df, on=\"item\", how=\"left\")[[\"id\", \"item\", \"freq\"]]\n",
    "element_freq = pd.DataFrame({\"element\": np.array(element_freq.index), \"freq\": np.array(element_freq, dtype=\"int\")})\n",
    "element_freq = pd.merge(element_freq, element_df, on=\"element\", how=\"left\")[[\"id\", \"element\", \"freq\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##要因-企業間のネットワークデータを生成\n",
    "#要因-企業間のネットワークを生成\n",
    "item_flag = pd.merge(scenario1[[\"f.item\"]], item_df[:item_df.shape[0]-1], left_on=\"f.item\", right_on=\"item\", how=\"left\")[[\"id\", \"item\"]]\n",
    "element_flag = pd.merge(scenario1[[\"f.element\"]], element_df[:element_df.shape[0]-1], \n",
    "                        left_on=\"f.element\", right_on=\"element\", how=\"left\")[[\"id\", \"element\"]]\n",
    "company_flag = pd.merge(scenario1[[\"c.ticker\"]], company_df, \n",
    "                        left_on=\"c.ticker\", right_on=\"ticker\", how=\"left\")[[\"id\", \"ticker\", \"company\"]]\n",
    "index_get = np.array(np.where((pd.isna(item_flag[\"id\"])==False) & \n",
    "                              (pd.isna(element_flag[\"id\"])==False) & (pd.isna(company_flag[\"id\"])==False))[0], dtype=\"int\")\n",
    "item_fc1 = np.array(item_flag[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "element_fc1 = np.array(element_flag[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "company_fc1 = np.array(company_flag[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "n1 = index_get.shape[0]\n",
    "\n",
    "#データフレームを作成\n",
    "temp_item = item_df.iloc[item_fc1]\n",
    "temp_item.columns = [\"item_id\", \"item\"]; temp_item.index = np.arange(temp_item.shape[0])\n",
    "temp_element = element_df.iloc[element_fc1]\n",
    "temp_element.columns = [\"element_id\", \"element\"]; temp_element.index = np.arange(temp_element.shape[0])\n",
    "temp_company = company_df.iloc[company_fc1]\n",
    "temp_company.columns = [\"company_id\", \"ticker\", \"company\"]; temp_company.index = np.arange(temp_company.shape[0])\n",
    "fc = pd.concat((temp_item, temp_element, temp_company), axis=1)\n",
    "del temp_item, temp_element, temp_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要因-要因間のネットワークを生成\n",
    "item_flag1 = pd.merge(factor[[\"f1.item\"]], item_df[:item_df.shape[0]-1], left_on=\"f1.item\", right_on=\"item\", how=\"left\")[[\"id\", \"item\"]]\n",
    "item_flag2 = pd.merge(factor[[\"f2.item\"]], item_df[:item_df.shape[0]-1], left_on=\"f2.item\", right_on=\"item\", how=\"left\")[[\"id\", \"item\"]]\n",
    "element_flag1 = pd.merge(factor[[\"f1.element\"]], element_df[:element_df.shape[0]-1], \n",
    "                         left_on=\"f1.element\", right_on=\"element\", how=\"left\")[[\"id\", \"element\"]] \n",
    "element_flag2 = pd.merge(factor[[\"f2.element\"]], element_df[:element_df.shape[0]-1], \n",
    "                         left_on=\"f2.element\", right_on=\"element\", how=\"left\")[[\"id\", \"element\"]]\n",
    "index_get = np.array(np.where((pd.isna(item_flag1[\"id\"])==False) & (pd.isna(item_flag2[\"id\"])==False) &\n",
    "                              (pd.isna(element_flag1[\"id\"])==False) & (pd.isna(element_flag2[\"id\"])==False))[0], dtype=\"int\")\n",
    "item_ff11 = np.array(item_flag1[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "item_ff12 = np.array(item_flag2[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "element_ff11 = np.array(element_flag1[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "element_ff12 = np.array(element_flag2[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "n2 = index_get.shape[0]\n",
    "\n",
    "#データフレームを作成\n",
    "temp_item1 = item_df.iloc[item_ff11]\n",
    "temp_item1.columns = [\"item_id1\", \"item1\"]; temp_item1.index = np.arange(temp_item1.shape[0])\n",
    "temp_item2 = item_df.iloc[item_ff12]\n",
    "temp_item2.columns = [\"item_id2\", \"item2\"]; temp_item2.index = np.arange(temp_item2.shape[0])\n",
    "temp_element1 = element_df.iloc[element_ff11]\n",
    "temp_element1.columns = [\"element_id1\", \"element1\"]; temp_element1.index = np.arange(temp_element1.shape[0])\n",
    "temp_element2 = element_df.iloc[element_ff12]\n",
    "temp_element2.columns = [\"element_id2\", \"element2\"]; temp_element2.index = np.arange(temp_element2.shape[0])\n",
    "ff = pd.concat((temp_item1, temp_element1, temp_item2, temp_element2), axis=1)\n",
    "del temp_item1, temp_item2, temp_element1, temp_element2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要因-要因-企業間のネットワークを生成\n",
    "item_flag1 = pd.merge(scenario2[[\"f1.item\"]], item_df[:item_df.shape[0]-1], left_on=\"f1.item\", right_on=\"item\", how=\"left\")[[\"id\", \"item\"]]\n",
    "item_flag2 = pd.merge(scenario2[[\"f2.item\"]], item_df[:item_df.shape[0]-1], left_on=\"f2.item\", right_on=\"item\", how=\"left\")[[\"id\", \"item\"]]\n",
    "element_flag1 = pd.merge(scenario2[[\"f1.element\"]], element_df[:element_df.shape[0]-1], \n",
    "                         left_on=\"f1.element\", right_on=\"element\", how=\"left\")[[\"id\", \"element\"]]\n",
    "element_flag2 = pd.merge(scenario2[[\"f2.element\"]], element_df[:element_df.shape[0]-1], \n",
    "                         left_on=\"f2.element\", right_on=\"element\", how=\"left\")[[\"id\", \"element\"]]\n",
    "company_flag = pd.merge(scenario2[[\"c.ticker\"]], company_df,\n",
    "                        left_on=\"c.ticker\", right_on=\"ticker\", how=\"left\")[[\"id\", \"ticker\", \"company\"]]\n",
    "index_get = np.array(np.where((pd.isna(item_flag1[\"id\"])==False) & (pd.isna(item_flag2[\"id\"])==False) &\n",
    "                              (pd.isna(element_flag1[\"id\"])==False) & (pd.isna(element_flag2[\"id\"])==False) & \n",
    "                              (pd.isna(company_flag[\"id\"])==False))[0], dtype=\"int\")\n",
    "item_ffc11 = np.array(item_flag1[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "item_ffc12 = np.array(item_flag2[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "element_ffc11 = np.array(element_flag1[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "element_ffc12 = np.array(element_flag2[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "company_ffc1 = np.array(company_flag[\"id\"].iloc[index_get], dtype=\"int16\")\n",
    "n3 = index_get.shape[0]\n",
    "\n",
    "#データフレームを作成\n",
    "temp_item1 = item_df.iloc[item_ffc11]\n",
    "temp_item1.columns = [\"item_id1\", \"item1\"]; temp_item1.index = np.arange(temp_item1.shape[0])\n",
    "temp_item2 = item_df.iloc[item_ffc12]\n",
    "temp_item2.columns = [\"item_id2\", \"item2\"]; temp_item2.index = np.arange(temp_item2.shape[0])\n",
    "temp_element1 = element_df.iloc[element_ffc11]\n",
    "temp_element1.columns = [\"element_id1\", \"element1\"]; temp_element1.index = np.arange(temp_element1.shape[0])\n",
    "temp_element2 = element_df.iloc[element_ffc12]\n",
    "temp_element2.columns = [\"element_id2\", \"element2\"]; temp_element2.index = np.arange(temp_element2.shape[0])\n",
    "temp_company = company_df.iloc[company_ffc1]\n",
    "temp_company.columns = [\"company_id\", \"ticker\", \"company\"]; temp_company.index = np.arange(temp_company.shape[0])\n",
    "ffc = pd.concat((temp_item1, temp_element1, temp_item2, temp_element2, temp_company), axis=1)\n",
    "del temp_item1, temp_item2, temp_element1, temp_element2, temp_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##要因-企業-要因のネットワークデータを生成\n",
    "#要因と企業を抽出\n",
    "item_flag = pd.merge(scenario1[[\"f.item\"]], item_df, left_on=\"f.item\", right_on=\"item\", how=\"left\")[[\"id\", \"item\"]]\n",
    "element_flag = pd.merge(scenario1[[\"f.element\"]], element_df, left_on=\"f.element\", right_on=\"element\", how=\"left\")[[\"id\", \"element\"]]\n",
    "company_flag = pd.merge(scenario1[[\"c.ticker\"]], company_df, \n",
    "                        left_on=\"c.ticker\", right_on=\"ticker\", how=\"left\")[[\"id\", \"ticker\", \"company\"]]\n",
    "index_get = np.array(np.where((pd.isna(item_flag[\"id\"])==False) & \n",
    "                              (pd.isna(element_flag[\"id\"])==False) & (pd.isna(company_flag[\"id\"])==False))[0], dtype=\"int\")\n",
    "\n",
    "#データの格納用リスト\n",
    "get_company = np.unique(company_fc1)\n",
    "n = get_company.shape[0]\n",
    "company_list = [i for i in range(n)]\n",
    "item_list1 = [i for i in range(n)]\n",
    "item_list2 = [i for i in range(n)]\n",
    "element_list1 = [i for i in range(n)]\n",
    "element_list2 = [i for i in range(n)]\n",
    "\n",
    "for i in range(n):\n",
    "    #対象のitemとelementを抽出\n",
    "    index = np.array(np.where(company_fc1==get_company[i])[0], dtype=\"int\")\n",
    "    get_item = item_fc1[index]\n",
    "    get_element = element_fc1[index]\n",
    "    if get_element.shape[0] <= 1:\n",
    "        company_list[i] = np.array([], dtype=\"int16\")\n",
    "        item_list1[i] = np.array([], dtype=\"int16\")\n",
    "        item_list2[i] = np.array([], dtype=\"int16\")\n",
    "        element_list1[i] = np.array([], dtype=\"int16\")\n",
    "        element_list2[i] = np.array([], dtype=\"int16\")\n",
    "        continue\n",
    "\n",
    "    #組み合わせを作成\n",
    "    m = get_item.shape[0]\n",
    "    get_combine1 = np.repeat(np.arange(m-1), np.arange(m-1)[::-1]+1)\n",
    "    index_del = np.array([], dtype=\"int\")\n",
    "    get_combine2 = np.array([], dtype=\"int\")\n",
    "    for j in range(m-1):\n",
    "        index_del = np.append(index_del, j) \n",
    "        get_combine2 = np.append(get_combine2, np.delete(np.arange(m), index_del))\n",
    "\n",
    "    #リストに格納\n",
    "    company_list[i] = np.repeat(get_company[i], get_combine1.shape[0])\n",
    "    item_list1[i] = get_item[get_combine1]\n",
    "    item_list2[i] = get_item[get_combine2]\n",
    "    element_list1[i] = get_element[get_combine1]\n",
    "    element_list2[i] = get_element[get_combine2]\n",
    "    \n",
    "#リストを変換\n",
    "company_fcf1 = np.array(list(itertools.chain(*[company_list[i] for i in range(n)])))\n",
    "item_fcf11 = np.array(list(itertools.chain(*[item_list1[i] for i in range(n)])))\n",
    "item_fcf12 = np.array(list(itertools.chain(*[item_list2[i] for i in range(n)])))\n",
    "element_fcf11 = np.array(list(itertools.chain(*[element_list1[i] for i in range(n)])))\n",
    "element_fcf12 = np.array(list(itertools.chain(*[element_list2[i] for i in range(n)])))\n",
    "n4 = company_fcf1.shape[0]\n",
    "\n",
    "#データフレームを作成\n",
    "temp_item1 = item_df.iloc[item_fcf11]\n",
    "temp_item1.columns = [\"item_id1\", \"item1\"]; temp_item1.index = np.arange(temp_item1.shape[0])\n",
    "temp_item2 = item_df.iloc[item_fcf12]\n",
    "temp_item2.columns = [\"item_id2\", \"item2\"]; temp_item2.index = np.arange(temp_item2.shape[0])\n",
    "temp_element1 = element_df.iloc[element_fcf11]\n",
    "temp_element1.columns = [\"element_id1\", \"element1\"]; temp_element1.index = np.arange(temp_element1.shape[0])\n",
    "temp_element2 = element_df.iloc[element_fcf12]\n",
    "temp_element2.columns = [\"element_id2\", \"element2\"]; temp_element2.index = np.arange(temp_element2.shape[0])\n",
    "temp_company = company_df.iloc[company_fcf1]\n",
    "temp_company.columns = [\"company_id\", \"ticker\", \"company\"]; temp_company.index = np.arange(temp_company.shape[0])\n",
    "fcf = pd.concat((temp_company, temp_item1, temp_element1, temp_item2, temp_element2), axis=1)\n",
    "del item_list1, item_list2, element_list1, element_list2, company_list\n",
    "del temp_item1, temp_item2, temp_element1, temp_element2, temp_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##企業-要因-企業のネットワークデータを生成\n",
    "#要因と企業を抽出\n",
    "item_flag = pd.merge(scenario1[[\"f.item\"]], item_df, left_on=\"f.item\", right_on=\"item\", how=\"left\")[[\"id\", \"item\"]]\n",
    "element_flag = pd.merge(scenario1[[\"f.element\"]], element_df, left_on=\"f.element\", right_on=\"element\", how=\"left\")[[\"id\", \"element\"]]\n",
    "company_flag = pd.merge(scenario1[[\"c.ticker\"]], company_df, \n",
    "                        left_on=\"c.ticker\", right_on=\"ticker\", how=\"left\")[[\"id\", \"ticker\", \"company\"]]\n",
    "index_get = np.array(np.where((pd.isna(item_flag[\"id\"])==False) & \n",
    "                              (pd.isna(element_flag[\"id\"])==False) & (pd.isna(company_flag[\"id\"])==False))[0], dtype=\"int\")\n",
    "\n",
    "#データの格納用リスト\n",
    "get_item = np.unique(item_fc1); get_item = get_item[:get_item.shape[0]-1]\n",
    "n = get_item.shape[0]\n",
    "item_list = [i for i in range(n)]\n",
    "company_list1 = [i for i in range(n)]\n",
    "company_list2 = [i for i in range(n)]\n",
    "\n",
    "for i in range(n):\n",
    "    #対象の企業を抽出\n",
    "    index = np.array(np.where(item_fc1==get_item[i])[0], dtype=\"int\")\n",
    "    get_company = company_fc1[index]\n",
    "    if get_element.shape[0] <= 1:\n",
    "        item_list[i] = np.array([], dtype=\"int16\")\n",
    "        company_list1[i] = np.array([], dtype=\"int16\")\n",
    "        company_list2[i] = np.array([], dtype=\"int16\")\n",
    "        continue\n",
    "\n",
    "    #組み合わせを作成\n",
    "    m = get_company.shape[0]\n",
    "    get_combine1 = np.repeat(np.arange(m-1), np.arange(m-1)[::-1]+1)\n",
    "    index_del = np.array([], dtype=\"int\")\n",
    "    get_combine2 = np.array([], dtype=\"int\")\n",
    "    for j in range(m-1):\n",
    "        index_del = np.append(index_del, j) \n",
    "        get_combine2 = np.append(get_combine2, np.delete(np.arange(m), index_del))\n",
    "\n",
    "    #リストに格納\n",
    "    item_list[i] = np.repeat(get_item[i], get_combine1.shape[0])\n",
    "    company_list1[i] = get_company[get_combine1]\n",
    "    company_list2[i] = get_company[get_combine2]\n",
    "    \n",
    "#リストを変換\n",
    "item_cfc1 = np.array(list(itertools.chain(*[item_list[i] for i in range(n)])))\n",
    "company_cfc11 = np.array(list(itertools.chain(*[company_list1[i] for i in range(n)])))\n",
    "company_cfc12 = np.array(list(itertools.chain(*[company_list2[i] for i in range(n)])))\n",
    "n5 = item_cfc1.shape[0]\n",
    "\n",
    "#データフレームを作成\n",
    "temp_item = item_df.iloc[item_cfc1]\n",
    "temp_item.columns = [\"item_id\", \"item\"]; temp_item.index = np.arange(temp_item.shape[0])\n",
    "temp_company1 = company_df.iloc[company_cfc11]\n",
    "temp_company1.columns = [\"company_id1\", \"ticker1\", \"company1\"]; temp_company1.index = np.arange(temp_company1.shape[0])\n",
    "temp_company2 = company_df.iloc[company_cfc12]\n",
    "temp_company2.columns = [\"company_id2\", \"ticker2\", \"company2\"]; temp_company2.index = np.arange(temp_company2.shape[0])\n",
    "cfc = pd.concat((temp_company1, temp_company2, temp_item), axis=1)\n",
    "del item_list, company_list1, company_list2\n",
    "del temp_item, temp_company1, temp_company2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データフレームを出力\n",
    "fc.to_excel(\"D:/Statistics/data/scenario_link/factor-company1.xlsx\")\n",
    "ff.to_excel(\"D:/Statistics/data/scenario_link/factor-factor1.xlsx\")\n",
    "ffc.to_excel(\"D:/Statistics/data/scenario_link/factor-factor-company1.xlsx\")\n",
    "fcf.to_excel(\"D:/Statistics/data/scenario_link/factor-company-factor1.xlsx\")\n",
    "cfc.to_excel(\"D:/Statistics/data/scenario_link/company-factor-company1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##負例サンプリングにより新しいサンプルを生成\n",
    "#サンプリング確率を設定\n",
    "s = 2\n",
    "item_prob = np.power(item_freq[\"freq\"], 0.75) / np.sum(np.power(item_freq[\"freq\"], 0.75))\n",
    "element_prob = np.power(element_freq[\"freq\"], 0.75) / np.sum(np.power(element_freq[\"freq\"], 0.75))\n",
    "company_prob = np.power(company_freq[\"freq\"], 0.75) / np.sum(np.power(company_freq[\"freq\"], 0.75))\n",
    "\n",
    "\n",
    "#要因-企業間の負例をサンプリング\n",
    "item_fc0 = np.array(np.dot(np.random.multinomial(1, item_prob, n1*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_fc0 = np.array(item_freq[\"id\"].iloc[item_fc0], dtype=\"int16\")\n",
    "element_fc0 = np.array(np.dot(np.random.multinomial(1, element_prob, n1*s), np.arange(element_prob.shape[0])), dtype=\"int16\")\n",
    "element_fc0 = np.array(element_freq[\"id\"].iloc[element_fc0], dtype=\"int16\")\n",
    "company_fc0 = np.array(np.dot(np.random.multinomial(1, company_prob, n1*s), np.arange(company_prob.shape[0])), dtype=\"int16\")\n",
    "company_fc0 = np.array(company_freq[\"id\"].iloc[company_fc0], dtype=\"int16\")\n",
    "\n",
    "#要因-要因間の負例をサンプリング\n",
    "item_ff01 = np.array(np.dot(np.random.multinomial(1, item_prob, n2*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_ff01 = np.array(item_freq[\"id\"].iloc[item_ff01], dtype=\"int16\")\n",
    "item_ff02 = np.array(np.dot(np.random.multinomial(1, item_prob, n2*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_ff02 = np.array(item_freq[\"id\"].iloc[item_ff02], dtype=\"int16\")\n",
    "element_ff01 = np.array(np.dot(np.random.multinomial(1, element_prob, n2*s), np.arange(element_prob.shape[0])), dtype=\"int16\")\n",
    "element_ff01 = np.array(element_freq[\"id\"].iloc[element_ff01], dtype=\"int16\")\n",
    "element_ff02 = np.array(np.dot(np.random.multinomial(1, element_prob, n2*s), np.arange(element_prob.shape[0])), dtype=\"int16\")\n",
    "element_ff02 = np.array(element_freq[\"id\"].iloc[element_ff02], dtype=\"int16\")\n",
    "\n",
    "#要因-要因-企業間の負例をサンプリング\n",
    "item_ffc01 = np.array(np.dot(np.random.multinomial(1, item_prob, n3*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_ffc01 = np.array(item_freq[\"id\"].iloc[item_ffc01], dtype=\"int16\")\n",
    "item_ffc02 = np.array(np.dot(np.random.multinomial(1, item_prob, n3*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_ffc02 = np.array(item_freq[\"id\"].iloc[item_ffc02], dtype=\"int16\")\n",
    "element_ffc01 = np.array(np.dot(np.random.multinomial(1, element_prob, n3*s), np.arange(element_prob.shape[0])), dtype=\"int16\")\n",
    "element_ffc01 = np.array(element_freq[\"id\"].iloc[element_ffc01], dtype=\"int16\")\n",
    "element_ffc02 = np.array(np.dot(np.random.multinomial(1, element_prob, n3*s), np.arange(element_prob.shape[0])), dtype=\"int16\")\n",
    "element_ffc02 = np.array(element_freq[\"id\"].iloc[element_ffc02], dtype=\"int16\")\n",
    "company_ffc0 = np.array(np.dot(np.random.multinomial(1, company_prob, n3*s), np.arange(company_prob.shape[0])), dtype=\"int16\")\n",
    "company_ffc0 = np.array(company_freq[\"id\"].iloc[company_ffc0], dtype=\"int16\")\n",
    "\n",
    "#要因-企業-要因間の負例をサンプリング\n",
    "item_fcf01 = np.array(np.dot(np.random.multinomial(1, item_prob, n4*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_fcf01 = np.array(item_freq[\"id\"].iloc[item_fcf01], dtype=\"int16\")\n",
    "item_fcf02 = np.array(np.dot(np.random.multinomial(1, item_prob, n4*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_fcf02 = np.array(item_freq[\"id\"].iloc[item_fcf02], dtype=\"int16\")\n",
    "element_fcf01 = np.array(np.dot(np.random.multinomial(1, element_prob, n4*s), np.arange(element_prob.shape[0])), dtype=\"int16\")\n",
    "element_fcf01 = np.array(element_freq[\"id\"].iloc[element_fcf01], dtype=\"int16\")\n",
    "element_fcf02 = np.array(np.dot(np.random.multinomial(1, element_prob, n4*s), np.arange(element_prob.shape[0])), dtype=\"int16\")\n",
    "element_fcf02 = np.array(element_freq[\"id\"].iloc[element_fcf02], dtype=\"int16\")\n",
    "company_fcf0 = np.array(np.dot(np.random.multinomial(1, company_prob, n4*s), np.arange(company_prob.shape[0])), dtype=\"int16\")\n",
    "company_fcf0 = np.array(company_freq[\"id\"].iloc[company_fcf0], dtype=\"int16\")\n",
    "\n",
    "#企業-要因-企業間の負例をサンプリング\n",
    "item_cfc0 = np.array(np.dot(np.random.multinomial(1, item_prob, n5*s), np.arange(item_prob.shape[0])), dtype=\"int16\")\n",
    "item_cfc0 = np.array(item_freq[\"id\"].iloc[item_cfc0], dtype=\"int16\")\n",
    "company_cfc01 = np.array(np.dot(np.random.multinomial(1, company_prob, n5*s), np.arange(company_prob.shape[0])), dtype=\"int16\")\n",
    "company_cfc01 = np.array(company_freq[\"id\"].iloc[company_cfc01], dtype=\"int16\")\n",
    "company_cfc02 = np.array(np.dot(np.random.multinomial(1, company_prob, n5*s), np.arange(company_prob.shape[0])), dtype=\"int16\")\n",
    "company_cfc02 = np.array(company_freq[\"id\"].iloc[company_cfc02], dtype=\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##応答変数を設定\n",
    "#要因-企業間の応答変数を定義\n",
    "item_fc = np.append(item_fc1, item_fc0)\n",
    "element_fc = np.append(element_fc1, element_fc0)\n",
    "company_fc = np.append(company_fc1, company_fc0)\n",
    "y1 = np.append(np.repeat(1, n1), np.repeat(0, n1*s))\n",
    "N1 = y1.shape[0]\n",
    "\n",
    "#要因-要因間の応答変数を定義\n",
    "item_ff1 = np.append(item_ff11, item_ff01)\n",
    "item_ff2 = np.append(item_ff12, item_ff02)\n",
    "element_ff1 = np.append(element_ff11, element_ff01)\n",
    "element_ff2 = np.append(element_ff12, element_ff02)\n",
    "y2 = np.append(np.repeat(1, n2), np.repeat(0, n2*s))\n",
    "N2 = y2.shape[0]\n",
    "\n",
    "#要因ー要因-企業間の応答変数を定義\n",
    "item_ffc1 = np.append(item_ffc11, item_ffc01)\n",
    "item_ffc2 = np.append(item_ffc12, item_ffc02)\n",
    "element_ffc1 = np.append(element_ffc11, element_ffc01)\n",
    "element_ffc2 = np.append(element_ffc12, element_ffc02)\n",
    "company_ffc = np.append(company_ffc1, company_ffc0)\n",
    "y3 = np.append(np.repeat(1, n3), np.repeat(0, n3*s))\n",
    "N3 = y3.shape[0]\n",
    "\n",
    "#要因ー企業-要因間の応答変数を定義\n",
    "item_fcf1 = np.append(item_fcf11, item_fcf01)\n",
    "item_fcf2 = np.append(item_fcf12, item_fcf02)\n",
    "element_fcf1 = np.append(element_fcf11, element_fcf01)\n",
    "element_fcf2 = np.append(element_fcf12, element_fcf02)\n",
    "company_fcf = np.append(company_fcf1, company_fcf0)\n",
    "y4 = np.append(np.repeat(1, n4), np.repeat(0, n4*s))\n",
    "N4 = y4.shape[0]\n",
    "\n",
    "#企業-要因-企業間の応答変数を定義\n",
    "item_cfc = np.append(item_cfc1, item_cfc0)\n",
    "company_cfc1 = np.append(company_cfc11, company_cfc01)\n",
    "company_cfc2 = np.append(company_cfc12, company_cfc02)\n",
    "y5 = np.append(np.repeat(1, n5), np.repeat(0, n5*s))\n",
    "N5 = y5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##学習データとテストデータに分割\n",
    "#要因-企業間のデータを分割\n",
    "split = 4/5\n",
    "index_learn = np.random.choice(N1, int(split * N1), replace=False)\n",
    "index_test = np.delete(np.arange(N1), index_learn)\n",
    "item_fc1 = item_fc[index_learn]; item_fc2 = item_fc[index_test]\n",
    "element_fc1 = element_fc[index_learn]; element_fc2 = element_fc[index_test]\n",
    "company_fc1 = company_fc[index_learn]; company_fc2 = company_fc[index_test]\n",
    "y11 = y1[index_learn]; y12 = y1[index_test]\n",
    "N11 = index_learn.shape[0]; N12 = index_test.shape[0]\n",
    "\n",
    "#要因-要因間のデータを分割\n",
    "index_learn = np.random.choice(N2, int(split * N2), replace=False)\n",
    "index_test = np.delete(np.arange(N2), index_learn)\n",
    "item_ff11 = item_ff1[index_learn]; item_ff12 = item_ff1[index_test]\n",
    "item_ff21 = item_ff2[index_learn]; item_ff22 = item_ff2[index_test]\n",
    "element_ff11 = element_ff1[index_learn]; element_ff12 = element_ff1[index_test]\n",
    "element_ff21 = element_ff2[index_learn]; element_ff22 = element_ff2[index_test]\n",
    "y21 = y2[index_learn]; y22 = y2[index_test]\n",
    "N21 = index_learn.shape[0]; N22 = index_test.shape[0]\n",
    "\n",
    "#要因-要因-企業間のデータを分割\n",
    "index_learn = np.random.choice(N3, int(split * N3), replace=False)\n",
    "index_test = np.delete(np.arange(N3), index_learn)\n",
    "item_ffc11 = item_ffc1[index_learn]; item_ff12 = item_ffc1[index_test]\n",
    "item_ffc21 = item_ffc2[index_learn]; item_ff22 = item_ffc2[index_test]\n",
    "element_ffc11 = element_ffc1[index_learn]; element_ffc12 = element_ffc1[index_test]\n",
    "element_ffc21 = element_ffc2[index_learn]; element_ffc22 = element_ffc2[index_test]\n",
    "company_ffc1 = company_ffc[index_learn]; company_ffc2 = company_ffc[index_test]\n",
    "y31 = y3[index_learn]; y32 = y3[index_test]\n",
    "N31 = index_learn.shape[0]; N32 = index_test.shape[0]\n",
    "\n",
    "#要因-企業-要因間のデータを分割\n",
    "index_learn = np.random.choice(N4, int(split * N4), replace=False)\n",
    "index_test = np.delete(np.arange(N4), index_learn)\n",
    "item_fcf11 = item_fcf1[index_learn]; item_fcf12 = item_fcf1[index_test]\n",
    "item_fcf21 = item_fcf2[index_learn]; item_fcf22 = item_fcf2[index_test]\n",
    "element_fcf11 = element_fcf1[index_learn]; element_fcf12 = element_fcf1[index_test]\n",
    "element_fcf21 = element_fcf2[index_learn]; element_fcf22 = element_fcf2[index_test]\n",
    "company_fcf1 = company_fcf[index_learn]; company_fcf2 = company_fcf[index_test]\n",
    "y41 = y4[index_learn]; y42 = y4[index_test]\n",
    "N41 = index_learn.shape[0]; N42 = index_test.shape[0]\n",
    "\n",
    "#企業-要因-企業間のデータを分割\n",
    "index_learn = np.random.choice(N5, int(split * N5), replace=False)\n",
    "index_test = np.delete(np.arange(N5), index_learn)\n",
    "item_cfc1 = item_cfc[index_learn]; item_cfc2 = item_cfc[index_test]\n",
    "company_cfc11 = company_cfc1[index_learn]; company_cfc12 = company_cfc1[index_test]\n",
    "company_cfc21 = company_cfc2[index_learn]; company_cfc22 = company_cfc2[index_test]\n",
    "y51 = y5[index_learn]; y52 = y5[index_test]\n",
    "N51 = index_learn.shape[0]; N52 = index_test.shape[0]\n",
    "N = [N11, N21, N31, N41, N51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##インデックスを設定\n",
    "#要因と企業のユニーク数\n",
    "item_n = item_df.shape[0]-1\n",
    "element_n = element_df.shape[0]-1\n",
    "company_n = company_df.shape[0]\n",
    "\n",
    "#itemのインデックスを設定\n",
    "item_list_fc = [i for i in range(item_n)]\n",
    "item_list_ff1 = [i for i in range(item_n)]\n",
    "item_list_ff2 = [i for i in range(item_n)]\n",
    "item_list_ffc1 = [i for i in range(item_n)]\n",
    "item_list_ffc2 = [i for i in range(item_n)]\n",
    "item_list_fcf1 = [i for i in range(item_n)]\n",
    "item_list_fcf2 = [i for i in range(item_n)]\n",
    "item_list_cfc = [i for i in range(item_n)]\n",
    "for i in range(item_n):\n",
    "    item_list_fc[i] = np.array(np.where(item_fc1==i)[0], dtype=\"int\")\n",
    "    item_list_ff1[i] = np.array(np.where(item_ff11==i)[0], dtype=\"int\")\n",
    "    item_list_ff2[i] = np.array(np.where(item_ff21==i)[0], dtype=\"int\")\n",
    "    item_list_ffc1[i] = np.array(np.where(item_ffc11==i)[0], dtype=\"int\")\n",
    "    item_list_ffc2[i] = np.array(np.where(item_ffc21==i)[0], dtype=\"int\")\n",
    "    item_list_fcf1[i] = np.array(np.where(item_fcf11==i)[0], dtype=\"int\")\n",
    "    item_list_fcf2[i] = np.array(np.where(item_fcf21==i)[0], dtype=\"int\")\n",
    "    item_list_cfc[i] = np.array(np.where(item_cfc1==i)[0], dtype=\"int\")\n",
    "    \n",
    "#elementのインデックスを設定\n",
    "element_list_fc = [i for i in range(element_n)]\n",
    "element_list_ff1 = [i for i in range(element_n)]\n",
    "element_list_ff2 = [i for i in range(element_n)]\n",
    "element_list_ffc1 = [i for i in range(element_n)]\n",
    "element_list_ffc2 = [i for i in range(element_n)]\n",
    "element_list_fcf1 = [i for i in range(element_n)]\n",
    "element_list_fcf2 = [i for i in range(element_n)]\n",
    "for i in range(element_n):\n",
    "    element_list_fc[i] = np.array(np.where(element_fc1==i)[0], dtype=\"int\")\n",
    "    element_list_ff1[i] = np.array(np.where(element_ff11==i)[0], dtype=\"int\")\n",
    "    element_list_ff2[i] = np.array(np.where(element_ff21==i)[0], dtype=\"int\")\n",
    "    element_list_ffc1[i] = np.array(np.where(element_ffc11==i)[0], dtype=\"int\")\n",
    "    element_list_ffc2[i] = np.array(np.where(element_ffc21==i)[0], dtype=\"int\")\n",
    "    element_list_fcf1[i] = np.array(np.where(element_fcf11==i)[0], dtype=\"int\")\n",
    "    element_list_fcf2[i] = np.array(np.where(element_fcf21==i)[0], dtype=\"int\")\n",
    "    \n",
    "#企業のインデックスを設定\n",
    "company_list_fc = [i for i in range(company_n)]\n",
    "company_list_ffc = [i for i in range(company_n)]\n",
    "company_list_fcf = [i for i in range(company_n)]\n",
    "company_list_cfc1 = [i for i in range(company_n)]\n",
    "company_list_cfc2 = [i for i in range(company_n)]\n",
    "for i in range(company_n):\n",
    "    company_list_fc[i] = np.array(np.where(company_fc1==i)[0], dtype=\"int\")\n",
    "    company_list_ffc[i] = np.array(np.where(company_ffc1==i)[0], dtype=\"int\")\n",
    "    company_list_fcf[i] = np.array(np.where(company_fcf1==i)[0], dtype=\"int\")\n",
    "    company_list_cfc1[i] = np.array(np.where(company_cfc11==i)[0], dtype=\"int\")\n",
    "    company_list_cfc2[i] = np.array(np.where(company_cfc21==i)[0], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "####マルコフ連鎖モンテカルロ法でパラメータを推定####\n",
    "##切断正規分布の乱数を発生させる関数\n",
    "def rtnorm(mu, sigma, a, b, n):\n",
    "    FA = norm.cdf(a, mu, sigma)\n",
    "    FB = norm.cdf(b, mu, sigma)\n",
    "    return norm.ppf(np.random.uniform(0, 1, n)*(FB-FA)+FA, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ベイジアン多変量回帰モデルをギブスサンプリングする関数\n",
    "def rmultireg(Y, X, inv_XXV, XY, Cov, ADelta, Deltabar, V, nu, n, col, k):\n",
    "    #事後分布のパラメータを設定\n",
    "    beta_mu = np.dot(inv_XXV, XY + np.dot(ADelta, Deltabar)).T.reshape(-1)   #平均ベクトル\n",
    "    sigma = np.kron(Cov, inv_XXV)   #分散共分散行列\n",
    "\n",
    "    #パラメータをサンプリング\n",
    "    beta_vec = np.random.multivariate_normal(beta_mu, sigma, 1)\n",
    "    beta = beta_vec.reshape(col, k, order='F')   #回帰行列に変換\n",
    "\n",
    "    \n",
    "    ##逆ウィシャート分布から分散共分散行列をサンプリング\n",
    "    #モデル誤差を設定\n",
    "    mu = np.dot(X, beta)\n",
    "    er = Y - mu\n",
    "\n",
    "    #逆ウィシャート分布のパラメータ\n",
    "    IW_R = np.dot(er.T, er) + V\n",
    "    Sn = n + nu\n",
    "\n",
    "    #パラメータをサンプリング\n",
    "    Cov = scipy.stats.invwishart.rvs(Sn, IW_R, 1)\n",
    "    return beta, Cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##アルゴリズムの設定\n",
    "type_n = 5\n",
    "k = 10\n",
    "k_vec = np.repeat(1, k)\n",
    "R = 1000\n",
    "keep = 2\n",
    "burnin = int(100/keep)\n",
    "iter = 0\n",
    "disp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##事前分布の設定\n",
    "#階層モデルの事前分布\n",
    "delta = np.repeat(0, k)\n",
    "V = 0.1 * np.diag(np.ones(k))\n",
    "nu = 1\n",
    "s01 = 0.1\n",
    "s01 = 0.1\n",
    "\n",
    "#モデルパラメータの事前分布\n",
    "alpha = np.repeat(0.0, k)\n",
    "tau = 100 \n",
    "s02 = 1.0\n",
    "v02 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##初期値の設定\n",
    "#階層モデルの初期値\n",
    "Cov_v = np.array(np.diag(np.repeat(0.5, k)), dtype=\"float32\"); inv_Cov_v = np.linalg.inv(Cov_v)\n",
    "Cov_i = np.array(np.diag(np.repeat(0.5, k)), dtype=\"float32\"); inv_Cov_i = np.linalg.inv(Cov_i)\n",
    "Cov_e = np.array(np.diag(np.repeat(0.5, k)), dtype=\"float32\"); inv_Cov_e = np.linalg.inv(Cov_e)\n",
    "\n",
    "#モデルパラメータの初期値\n",
    "Sigma = np.array([1.0], dtype=\"float32\")\n",
    "beta = np.array(np.repeat(0.0, type_n), dtype=\"float32\")\n",
    "theta_v = np.random.multivariate_normal(alpha, np.diag(np.repeat(0.1, k)), company_n)\n",
    "theta_i = np.array(np.vstack((np.random.multivariate_normal(alpha, np.diag(np.repeat(0.1, k)), item_n), np.repeat(1, k))), dtype=\"float32\")\n",
    "theta_e = np.array(np.vstack((np.random.multivariate_normal(alpha, np.diag(np.repeat(0.1, k)), element_n), np.repeat(1, k))), dtype=\"float32\")\n",
    "omega_fc = np.array(np.random.normal(0, 0.1, k*k).reshape(k, k), dtype=\"float32\")\n",
    "omega_ff = np.array(np.random.normal(0, 0.1, k*k).reshape(k, k), dtype=\"float32\")\n",
    "omega_ffc = np.array(np.random.normal(0, 0.1, k*k*k).reshape(k, k, k), dtype=\"float32\")\n",
    "omega_fcf = np.array(np.random.normal(0, 0.1, k*k*k).reshape(k, k, k), dtype=\"float32\")\n",
    "omega_cfc = np.array(np.random.normal(0, 0.1, k*k*k).reshape(k, k, k), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##データの設定\n",
    "#切断領域を定義\n",
    "rho = 10.0\n",
    "y = [y11, y21, y31, y41, y51]\n",
    "a = [j for j in range(type_n)]\n",
    "b = [j for j in range(type_n)]\n",
    "for j in range(type_n):\n",
    "    a[j] = np.array((1-y[j] )*(-rho) + y[j]*0, dtype=\"float32\")\n",
    "    b[j] = np.array(y[j]*rho + (1-y[j])*0, dtype=\"float32\")\n",
    "    \n",
    "#特徴行列の割当インデックス\n",
    "allocation_theta = np.repeat(np.arange(k), k)\n",
    "allocation_omega = np.array([np.delete(np.arange(k), j).tolist() for j in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "####ギブスサンプリングでパラメータをサンプリング####\n",
    "\n",
    "##切断正規分布から潜在効用を生成\n",
    "#特徴ベクトルをidで対応付ける\n",
    "theta_item1 = theta_i[item_fc1, ]; theta_element1 = theta_e[element_fc1, ]; theta_company1 = theta_v[company_fc1, ]\n",
    "theta_item21 = theta_i[item_ff11, ]; theta_item22 = theta_i[item_ff21, ]\n",
    "theta_element21 = theta_e[element_ff11, ]; theta_element22 = theta_v[element_ff21, ]\n",
    "theta_item31 = theta_i[item_ffc11, ]; theta_item32 = theta_i[item_ffc21, ]\n",
    "theta_element31 = theta_e[element_ffc11, ]; theta_element32 = theta_e[element_ffc21, ]; theta_company3 = theta_v[company_ffc1, ]\n",
    "theta_item41 = theta_i[item_fcf11, ]; theta_item42 = theta_i[item_fcf21, ]\n",
    "theta_element41 = theta_e[element_fcf11, ]; theta_element42 = theta_e[element_fcf21, ]; theta_company4 = theta_v[company_fcf1, ]\n",
    "theta_item5 = theta_i[item_cfc1, ]; theta_company51 = theta_v[company_cfc11, ]; theta_company52 = theta_v[company_cfc21, ]\n",
    "\n",
    "#タッカー分解の期待値\n",
    "uv1 = np.dot(np.dot(theta_item1 * theta_element1, omega_fc) * theta_company1, k_vec)\n",
    "uv2 = np.dot(np.dot(theta_item21 * theta_element21, omega_ff) * (theta_item22 * theta_element22), k_vec)\n",
    "uv3 = np.array(np.repeat(0.0, N31), dtype=\"float32\")\n",
    "uv4 = np.array(np.repeat(0.0, N41), dtype=\"float32\")\n",
    "uv5 = np.array(np.repeat(0.0, N51), dtype=\"float32\")\n",
    "theta_joint31 = theta_item31 * theta_element31; theta_joint32 = theta_item32 * theta_element32\n",
    "theta_joint41 = theta_item41 * theta_element41; theta_joint42 = theta_item42 * theta_element42\n",
    "for j in range(k):\n",
    "    uv3 += np.dot(np.dot(theta_joint31, omega_ffc[:, :, j]) * theta_joint32 * theta_company3[:, j][:, np.newaxis], k_vec)\n",
    "    uv4 += np.dot(np.dot(theta_joint41, omega_fcf[:, :, j]) * theta_company4 * theta_joint41[:, j][:, np.newaxis], k_vec)\n",
    "    uv5 += np.dot(np.dot(theta_company51, omega_cfc[:, :, j]) * theta_item5 * theta_company52[:, j][:, np.newaxis], k_vec)\n",
    "uv = [uv1, uv2, uv3, uv4, uv5]\n",
    "\n",
    "#潜在効用を生成\n",
    "mu = [j for j in range(type_n)]\n",
    "U = [j for j in range(type_n)]\n",
    "for j in range(type_n):\n",
    "    mu[j] = beta[j] + uv[j]\n",
    "    U[j] = np.array(rtnorm(mu[j], Sigma, a[j], b[j], N[j]), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##モデルの期待値をサンプリング\n",
    "for j in range(type_n):\n",
    "    #モデル誤差を定義\n",
    "    er_y = U[j] - uv[j]\n",
    "\n",
    "    #正規分布から期待値をサンプリング\n",
    "    weights = np.power(tau, 2) / (Sigma/N[j] + np.power(tau, 2))\n",
    "    mu_par = weights * np.mean(er_y)\n",
    "    beta[j] = np.random.normal(mu_par, weights*Sigma/N[j], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.012834349941271254"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##アイテムの特徴ベクトルをサンプリング\n",
    "\n",
    "\n",
    "d = np.repeat(1, k)\n",
    "i = 0\n",
    "np.sum((np.dot(d, omega_fc) * d) * theta_item1[i, ] * theta_element1[i, ] * theta_company1[i, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "temp_index = np.sort(np.append(item_list_ff1[i], item_list_ff2[i]))\n",
    "index_dup = np.array(np.where(pd.Series(temp_index).duplicated())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "temp_index = np.sort(np.append(element_list_ff1[i], element_list_ff2[i]))\n",
    "index_dup = np.array(np.where(pd.Series(temp_index).duplicated())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'element_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-83e71651287b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0melement_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'element_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
